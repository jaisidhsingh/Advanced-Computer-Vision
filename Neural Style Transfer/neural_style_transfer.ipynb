{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "neural_style_transfer.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JswXjt-6AMLP"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as T\n",
        "from torchvision import models\n",
        "from torchvision.utils import save_image\n",
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BdOMk_PAk-f"
      },
      "source": [
        "# initialize our model (VGG with the fully connected removed and the weights frozen)\n",
        "class VggBackbone(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(VggBackbone, self).__init__()\n",
        "    self.chosen_layer_outputs = [\"0\", \"5\", \"10\", \"19\", \"28\"]\n",
        "    self.model = models.vgg19(pretrained=True).features[:29]\n",
        "  \n",
        "  def forward(self, x):\n",
        "    features = []\n",
        "    for layer_idx, layer in enumerate(self.model):\n",
        "      x = layer(x)\n",
        "      if str(layer_idx) in self.chosen_layer_outputs:\n",
        "        features.append(x)\n",
        "    \n",
        "    return features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ljJvtyRCbYH"
      },
      "source": [
        "def load_image_tensor(image_path, transforms, device):\n",
        "  image = Image.open(image_path)\n",
        "  image_tensor = transforms(image).unsqueeze(0)\n",
        "  return image_tensor.to(device)\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "image_dim = 356\n",
        "\n",
        "transforms = T.Compose([T.Resize((image_dim, image_dim)), T.ToTensor()])\n",
        "\n",
        "content = load_image_tensor(\"content2.jpg\", transforms, DEVICE)\n",
        "style = load_image_tensor(\"style.jpg\", transforms, DEVICE)\n",
        "generated = content.clone().requires_grad_(True)\n",
        "\n",
        "\n",
        "model = VggBackbone().to(DEVICE).eval()\n",
        "\n",
        "# Hyperparameters\n",
        "EPOCHS = 6001\n",
        "LR = 0.001\n",
        "alpha = 1\n",
        "beta = 0.1\n",
        "optimizer = optim.Adam([generated], lr=LR)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQOs4b-iEL2i",
        "outputId": "d71fc5c5-3b8e-4b8a-eeee-2cb10ba2ad28"
      },
      "source": [
        "# Training Loop\n",
        "for epoch in range(EPOCHS):\n",
        "  content_features = model(content)\n",
        "  style_features = model(style)\n",
        "  gen_features = model(generated)\n",
        "  SG_loss = 0\n",
        "  CG_loss = 0\n",
        "\n",
        "  for (content_feat, style_feat, gen_feat) in zip(content_features, style_features, gen_features):\n",
        "    N, C, H, W = gen_feat.shape\n",
        "    CG_loss += torch.mean((gen_feat - content_feat)**2)\n",
        "\n",
        "    # Make Gram Matrices:\n",
        "    style_gram = style_feat.view(C, H*W).mm(style_feat.view(C, H*W).t())\n",
        "    gen_gram = gen_feat.view(C, H*W).mm(gen_feat.view(C, H*W).t())\n",
        "    SG_loss = torch.mean((gen_gram - style_gram)**2)\n",
        "    \n",
        "  loss = alpha*CG_loss + beta*SG_loss\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if epoch % 1000 == 0:\n",
        "    print(\"Loss : \", loss)\n",
        "    save_image(generated, f\"generated{epoch//1000}.png\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss :  tensor(471415.4062, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Loss :  tensor(558.2444, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Loss :  tensor(395.1545, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Loss :  tensor(322.5838, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Loss :  tensor(306.1647, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Loss :  tensor(251.8336, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "Loss :  tensor(239.7029, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dwaBSLoGccY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}